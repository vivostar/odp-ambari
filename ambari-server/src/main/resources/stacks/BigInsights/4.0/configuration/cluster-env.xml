<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->

<configuration>
    <property>
      <name>recovery_enabled</name>
      <value>true</value>
      <description>Auto start enabled or not for this cluster.</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
      <name>recovery_type</name>
      <value>AUTO_START</value>
      <description>Auto start type.</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
      <name>recovery_lifetime_max_count</name>
      <value>1024</value>
      <description>Auto start lifetime maximum count of recovery attempt allowed per host component. This is reset when agent is restarted.</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
      <name>recovery_max_count</name>
      <value>6</value>
      <description>Auto start maximum count of recovery attempt allowed per host component in a window. This is reset when agent is restarted.</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
      <name>recovery_window_in_minutes</name>
      <value>60</value>
      <description>Auto start recovery window size in minutes.</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
      <name>recovery_retry_interval</name>
      <value>5</value>
      <description>Auto start recovery retry gap between tries per host component.</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>security_enabled</name>
        <value>false</value>
        <description>Hadoop Security</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>kerberos_domain</name>
        <value>EXAMPLE.COM</value>
        <description>Kerberos realm.</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>ignore_groupsusers_create</name>
        <display-name>Skip group modifications during install</display-name>
        <value>false</value>
        <description>Whether to ignore failures on users and group creation</description>
        <on-ambari-upgrade add="true"/>
        <property-type>ADDITIONAL_USER_PROPERTY</property-type>
        <value-attributes>
            <overridable>false</overridable>
            <type>boolean</type>
        </value-attributes>
    </property>
    <property>
        <name>smokeuser</name>
        <display-name>Smoke User</display-name>
        <value>ambari-qa</value>
        <on-ambari-upgrade add="true"/>
        <property-type>USER</property-type>
        <description>User executing service checks</description>
        <value-attributes>
            <type>user</type>
            <overridable>false</overridable>
        </value-attributes>
      </property>
    <property>
        <name>smokeuser_keytab</name>
        <value>/etc/security/keytabs/smokeuser.headless.keytab</value>
        <description>Path to smoke test user keytab file</description>
      <on-ambari-upgrade add="true"/>
    </property>
    <property>
        <name>user_group</name>
        <display-name>Hadoop Group</display-name>
        <value>hadoop</value>
        <on-ambari-upgrade add="true"/>
        <property-type>GROUP</property-type>
        <description>Hadoop user group.</description>
    </property>

  <!-- The properties that end in tar_source describe the pattern of where the tar.gz files come from.
  They will replace {{ iop_stack_version }} with the "#.#.#.#" value followed by -* (which is the build number in HDP 2.2).
  When copying those tarballs, Ambari will look up the corresponding tar_destination_folder property to know where it
  should be copied to.
  All of the destination folders must begin with hdfs://
  Please note that the spaces inside of {{ ... }} are important.

  IMPORTANT: Any properties included here must also be declared in site_properties.js

  -->
  <!-- Tez tarball is needed by Hive Server when using the Tez execution engine. -->
  <!-- <property>
    <name>tez_tar_source</name>
    <value>/usr/iop/current/tez-client/lib/tez.tar.gz</value>
    <description>Source file path that uses dynamic variables and regex to copy the file to HDFS.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>tez_tar_destination_folder</name>
    <value>hdfs:///iop/apps/{{ stack_version }}/tez/</value>
    <description>Destination HDFS folder for the file.</description>
    <on-ambari-upgrade add="true"/>
  </property>  -->

  <!-- Hive tarball is needed by WebHCat. -->
  <property>
    <name>hive_tar_source</name>
    <value>/usr/iop/current/hive-client/hive.tar.gz</value>
    <description>Source file path that uses dynamic variables and regex to copy the file to HDFS.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>hive_tar_destination_folder</name>
    <value>hdfs:///iop/apps/{{ stack_version }}/hive/</value>
    <description>Destination HDFS folder for the file.</description>
    <on-ambari-upgrade add="true"/>
  </property>

  <!-- Pig tarball is needed by WebHCat. -->
  <property>
    <name>pig_tar_source</name>
    <value>/usr/iop/current/pig-client/pig.tar.gz</value>
    <description>Source file path that uses dynamic variables and regex to copy the file to HDFS.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>pig_tar_destination_folder</name>
    <value>hdfs:///iop/apps/{{ stack_version }}/pig/</value>
    <description>Destination HDFS folder for the file.</description>
    <on-ambari-upgrade add="true"/>
  </property>

  <!-- Hadoop Streaming jar is needed by WebHCat. -->
  <property>
    <name>hadoop-streaming_tar_source</name>
    <value>/usr/iop/current/hadoop-mapreduce-client/hadoop-streaming.jar</value>
    <description>Source file path that uses dynamic variables and regex to copy the file to HDFS.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>hadoop-streaming_tar_destination_folder</name>
    <value>hdfs:///iop/apps/{{ stack_version }}/mapreduce/</value>
    <description>Destination HDFS folder for the file.</description>
    <on-ambari-upgrade add="true"/>
  </property>

  <!-- Sqoop tarball is needed by WebHCat. -->
  <property>
    <name>sqoop_tar_source</name>
    <value>/usr/iop/current/sqoop-client/sqoop.tar.gz</value>
    <description>Source file path that uses dynamic variables and regex to copy the file to HDFS.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>sqoop_tar_destination_folder</name>
    <value>hdfs:///iop/apps/{{ stack_version }}/sqoop/</value>
    <description>Destination HDFS folder for the file.</description>
    <on-ambari-upgrade add="true"/>
  </property>

  <!-- MapReduce2 tarball -->
  <property>
    <name>mapreduce_tar_source</name>
    <value>/usr/iop/current/hadoop-client/mapreduce.tar.gz</value>
    <description>Source file path that uses dynamic variables and regex to copy the file to HDFS.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>mapreduce_tar_destination_folder</name>
    <value>hdfs:///iop/apps/{{ stack_version }}/mapreduce/</value>
    <description>Destination HDFS folder for the file.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  
  <property>
    <name>repo_suse_rhel_template</name>
    <value>[{{repo_id}}]
name={{repo_id}}
{% if mirror_list %}mirrorlist={{mirror_list}}{% else %}baseurl={{base_url}}{% endif %}

path=/
enabled=1
gpgcheck=0</value>
    <description>Template of repositories for rhel and suse.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>repo_ubuntu_template</name>
    <value>{{package_type}} {{base_url}} {{components}}</value>
    <description>Template of repositories for ubuntu.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  
  <property>
    <name>override_uid</name>
    <display-name>Have Ambari manage UIDs</display-name>
    <value>true</value>
    <on-ambari-upgrade add="true"/>
    <property-type>ADDITIONAL_USER_PROPERTY</property-type>
    <description>Have Ambari manage UIDs</description>
    <value-attributes>
        <overridable>false</overridable>
        <type>boolean</type>
    </value-attributes>
  </property>
  
  <property>
    <name>fetch_nonlocal_groups</name>
    <value>true</value>
    <display-name>Ambari fetch nonlocal groups</display-name>
    <description>Ambari requires fetching all the groups. This can be slow
        on envs with enabled ldap. Setting this option to false will enable Ambari,
        to skip user/group management connected with ldap groups.</description>
    <value-attributes>
      <overridable>false</overridable>
      <type>boolean</type>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  
  <property>
    <name>managed_hdfs_resource_property_names</name>
    <value/>
    <description>Comma separated list of property names with HDFS resource paths.
        Resource from this list will be managed even if it is marked as not managed in the stack</description>
    <value-attributes>
      <overridable>false</overridable>
      <empty-value-valid>true</empty-value-valid>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>

  <!-- Define stack_name property in the base stack. DO NOT override this property for each stack version -->
  <property>
    <name>stack_name</name>
    <value>BigInsights</value>
    <description>The name of the stack.</description>
    <value-attributes>
      <read-only>true</read-only>
      <overridable>false</overridable>
      <visible>false</visible>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>

  <!-- Define stack_tools property in the base stack. DO NOT override this property for each stack version -->
  <property>
    <name>stack_tools</name>
    <value/>
    <description>Stack specific tools</description>
    <property-type>VALUE_FROM_PROPERTY_FILE</property-type>
    <value-attributes>
      <property-file-name>stack_tools.json</property-file-name>
      <property-file-type>json</property-file-type>
      <read-only>true</read-only>
      <overridable>false</overridable>
      <visible>false</visible>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <!-- Define stack_features property in the base stack. DO NOT override this property for each stack version -->
  <property>
    <name>stack_features</name>
    <value/>
    <description>List of features supported by the stack</description>
    <property-type>VALUE_FROM_PROPERTY_FILE</property-type>
    <value-attributes>
      <property-file-name>stack_features.json</property-file-name>
      <property-file-type>json</property-file-type>
      <read-only>true</read-only>
      <overridable>false</overridable>
      <visible>false</visible>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <!-- Define stack_packages property in the base stack. DO NOT override this property for each stack version -->
  <property>
    <name>stack_packages</name>
    <value/>
    <description>Associations between component and stack-select tools.</description>
    <property-type>VALUE_FROM_PROPERTY_FILE</property-type>
    <value-attributes>
      <property-file-name>stack_packages.json</property-file-name>
      <property-file-type>json</property-file-type>
      <read-only>true</read-only>
      <overridable>false</overridable>
      <visible>false</visible>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>stack_root</name>
    <value>{"BigInsights":"/usr/iop"}</value>
    <description>JSON which defines the stack root by stack name</description>  
    <value-attributes>
      <read-only>false</read-only>
      <overridable>false</overridable>
      <visible>false</visible>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>alerts_repeat_tolerance</name>
    <value>1</value>
    <description>The number of consecutive alerts required to transition an alert from the SOFT to the HARD state.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>ignore_bad_mounts</name>
    <value>false</value>
    <description>For properties handled by handle_mounted_dirs this will make Ambari not to create any directories.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>create_dirs_on_root</name>
    <value>true</value>
    <description>For properties handled by handle_mounted_dirs this will make Ambari to create not-existent unknown directories on / partition</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>one_dir_per_partition</name>
    <value>true</value>
    <description>For properties handled by handle_mounted_dirs this will make Ambari </description>
    <on-ambari-upgrade add="true"/>
  </property>
  
</configuration>
