<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
   Licensed to the Apache Software Foundation (ASF) under one or more
   contributor license agreements.  See the NOTICE file distributed with
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
-->
<!-- Put site-specific property overrides in this file. -->
<configuration supports_final="true">

  <property>
    <name>dfs.namenode.acls.enabled</name>
    <value>true</value>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.namenode.audit.log.async</name>
    <value>true</value>
    <description>Whether to enable async auditlog</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.namenode.fslock.fair</name>
    <value>false</value>
    <description>Whether fsLock is fair</description>
    <on-ambari-upgrade add="true"/>
  </property>
   <property>
    <name>dfs.namenode.startup.delay.block.deletion.sec</name>
    <value>3600</value>
    <description/>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/hadoop/hdfs/journalnode</value>
    <description>The path where the JournalNode daemon will store its local state. </description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.client.retry.policy.enabled</name>
    <value>false</value>
    <description>Enables HDFS client retry in the event of a NameNode failure.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.content-summary.limit</name>
    <value>5000</value>
    <description>Dfs content summary limit.</description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.encryption.key.provider.uri</name>
    <value/>
    <value-attributes>
      <empty-value-valid>true</empty-value-valid>
    </value-attributes>
    <depends-on>
      <property>
        <type>hadoop-env</type>
        <name>keyserver_host</name>
      </property>
      <property>
        <type>hadoop-env</type>
        <name>keyserver_port</name>
      </property>
      <property>
        <type>kms-env</type>
        <name>kms_port</name>
      </property>
      <property>
        <type>ranger-kms-site</type>
        <name>ranger.service.https.attrib.ssl.enabled</name>
      </property>
    </depends-on>
    <on-ambari-upgrade add="true"/>
  </property>
    <property>
    <name>nfs.file.dump.dir</name>
    <value>/tmp/.hdfs-nfs</value>
    <display-name>NFSGateway dump directory</display-name>
    <description>
      This directory is used to temporarily save out-of-order writes before
      writing to HDFS. For each file, the out-of-order writes are dumped after
      they are accumulated to exceed certain threshold (e.g., 1MB) in memory.
      One needs to make sure the directory has enough space.
    </description>
    <value-attributes>
      <type>directory</type>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>nfs.exports.allowed.hosts</name>
    <value>* rw</value>
    <display-name>Allowed hosts</display-name>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer.cipher.suites</name>
    <value>AES/CTR/NoPadding</value>
    <description>
      This value may be either undefined or AES/CTR/NoPadding. If defined, then 
      dfs.encrypt.data.transfer uses the specified cipher suite for data encryption. 
      If not defined, then only the algorithm specified in dfs.encrypt.data.transfer.algorithm 
      is used. By default, the property is not defined.
    </description>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.namenode.inode.attributes.provider.class</name>
    <description>Enable ranger hdfs plugin</description>
    <depends-on>
      <property>
        <type>ranger-hdfs-plugin-properties</type>
        <name>ranger-hdfs-plugin-enabled</name>
      </property>
    </depends-on>
    <value-attributes>
      <overridable>false</overridable>
    </value-attributes>
    <on-ambari-upgrade add="true"/>
  </property>
  <property>
    <name>dfs.namenode.accesstime.precision</name>
    <value>3600000</value>
    <display-name>Access time precision</display-name>
    <description>The access time for HDFS file is precise upto this value.
      The default value is 1 hour. Setting a value of 0 disables
      access times for HDFS.
    </description>
    <on-ambari-upgrade add="true"/>
    <value-attributes>
      <type>int</type>
    </value-attributes>
  </property>
</configuration>
